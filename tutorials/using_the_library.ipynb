{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "482707af",
   "metadata": {},
   "source": [
    "### Importing the Environment Setting component modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4911930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from irec.environment.loader.full_data import FullData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18910ac0",
   "metadata": {},
   "source": [
    "### Importing the Recommendation Agent component modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd6a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from irec.recommendation.agents.simple_agent import SimpleAgent\n",
    "from irec.recommendation.agents.action_selection_policies.egreedy import ASPEGreedy\n",
    "from irec.recommendation.agents.value_functions.e_greedy import EGreedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a75bf9e",
   "metadata": {},
   "source": [
    "### Importing the Experimental Evaluation component modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "545543b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from irec.offline_experiments.evaluation_policies.fixed_interaction import FixedInteraction\n",
    "from irec.offline_experiments.metric_evaluators.user_cumulative_interaction import UserCumulativeInteraction\n",
    "from irec.offline_experiments.metrics.hits import Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c36269",
   "metadata": {},
   "source": [
    "### Setting the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "407d79b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying splitting strategy: global\n",
      "\n",
      "Test shape: (16892, 4)\n",
      "Train shape: (80393, 4)\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "dataset = {\n",
    "    'path': \"./app/data/datasets/MovieLens 100k/ratings.csv\",\n",
    "    'random_seed': 0,\n",
    "    'file_delimiter': \",\",\n",
    "    'skip_head': True\n",
    "}\n",
    "# Splitting\n",
    "splitting = {'strategy': \"global\", 'train_size': 0.8, 'test_consumes': 5}\n",
    "# Loader\n",
    "loader = FullData(dataset, splitting)\n",
    "train_dataset, test_dataset, _, _ = loader.process()\n",
    "# Value Function\n",
    "value_function = EGreedy()\n",
    "# Action Selection Policy\n",
    "greedy_selection = ASPEGreedy(epsilon=0.001)\n",
    "# Agent\n",
    "agent = SimpleAgent(value_function, greedy_selection, name=\"EGreedy\")\n",
    "# Evaluation Policy\n",
    "eval_policy = FixedInteraction(num_interactions=100, interaction_size=1, save_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99cdd13",
   "metadata": {},
   "source": [
    "### Running and Evaluating the Performance of a MAB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54a07186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting EGreedy Training\n",
      "Ended EGreedy Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EGreedy: 100%|█████████████████████████████████████████████| 18900/18900 [00:01<00:00, 13574.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing interaction 5 with UserCumulativeInteraction\n",
      "Computing interaction 10 with UserCumulativeInteraction\n",
      "Computing interaction 20 with UserCumulativeInteraction\n",
      "Computing interaction 50 with UserCumulativeInteraction\n",
      "Computing interaction 100 with UserCumulativeInteraction\n",
      "UserCumulativeInteraction spent 0.31 seconds executing Hits metric\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Running the agent\n",
    "interactions, action_info = eval_policy.evaluate(agent, train_dataset, test_dataset)\n",
    "# Evaluation Setup\n",
    "evaluator = UserCumulativeInteraction(\n",
    "    ground_truth_dataset=test_dataset,\n",
    "    num_interactions=100,\n",
    "    interaction_size=1,\n",
    "    interactions_to_evaluate=[5, 10, 20, 50, 100],\n",
    "    relevance_evaluator_threshold=3.99\n",
    ")\n",
    "# Getting the results\n",
    "hits_values = evaluator.evaluate(metric_class=Hits, results=interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55901cb",
   "metadata": {},
   "source": [
    "### Viewing the results obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4c32daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados para métrica de Hits:\n",
      "top-5: 1.216931216931217\n",
      "top-10: 2.17989417989418\n",
      "top-20: 3.888888888888889\n",
      "top-50: 8.455026455026456\n",
      "top-100: 14.412698412698413\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nResults for Hits metric:\")\n",
    "print(\"top-5:\", np.mean(list(hits_values[0].values())))\n",
    "print(\"top-10:\", np.mean(list(hits_values[1].values())))\n",
    "print(\"top-20:\", np.mean(list(hits_values[2].values())))\n",
    "print(\"top-50:\", np.mean(list(hits_values[3].values())))\n",
    "print(\"top-100:\", np.mean(list(hits_values[4].values())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
